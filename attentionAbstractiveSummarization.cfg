[Logging]
log_level = info
log_file = /home/shantanu/PycharmProjects/DynetAttentionAbstractiveSummarizerRush/attentionAbstractiveSummarization.log
logger = AbstractiveSummarization

[Data]
data_dir = /home/shantanu/PycharmProjects/DynetAttentionAbstractiveSummarizerRush/data
train_article_file = train.article.txt
train_title_file = train.title.txt
valid_article_file = valid.article.filter.txt
valid_title_file = valid.title.filter.txt
generated_data_dir = /home/shantanu/PycharmProjects/DynetAttentionAbstractiveSummarizerRush/generated_data
w2i_file = aas_w2i.txt
i2w_file = aas_i2w.txt
train_article_save_file = train_article_save.txt
train_title_save_file = train_title_save.txt
valid_article_save_file = valid_article_save.txt
valid_title_save_file = valid_title_save.txt
max_train_data_points = 1
max_valid_data_points = None
max_test_data_points = None
max_sent_length = 200
min_sent_length = 1
bos_sym = <s>
eos_sym = </s>
unk_sym = <unk>
should_load_saved_data = true

[ExecutionMode]
execution_mode = training

[Model]
word_emb_size = 200
context_win_size = 5
hidden_layer_size = 400

